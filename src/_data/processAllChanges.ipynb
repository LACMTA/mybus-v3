{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES TO UPDATE FOR EACH SHAKEUP:\n",
    "\n",
    "TRANSLATION_FILE = 'DecemberServiceChanges_ForTranslation_110722.xlsx'\n",
    "TRANLSATION_LANGUAGES = {\n",
    "    'ENGLISH': 'en',\n",
    "    'SPANISH': 'es',\n",
    "    'CHINESE': 'zh-tw',\n",
    "    'KOREAN': 'ko',\n",
    "    'VIETNAMESE': 'vi',\n",
    "    'JAPANESE': 'ja',\n",
    "    'RUSSIAN': 'ru',\n",
    "    'ARMENIAN': 'hy'\n",
    "}\n",
    "\n",
    "INTRO_ROWS = [0, 1, 2]\n",
    "\n",
    "SUMMARY_START = 3\n",
    "SUMMARY_END = 7\n",
    "\n",
    "DETAIL_START = 8\n",
    "\n",
    "GTFS_ROUTES_URL = 'https://gitlab.com/LACMTA/gtfs_bus/-/raw/master/routes.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the Excel file with all the translations of the TakeOne, and put it in the `_data` folder, renamed to `allChanges.xlsx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas uses the xlrd package by default, but xlrd has removed support for xlsx files\n",
    "# thus we need to install and use openpyxl and set that to the engine used by read_excel()\n",
    "source_df = pd.read_excel(TRANSLATION_FILE, engine = 'openpyxl')\n",
    "source_df.rename(columns=lambda x: x.strip())\n",
    "\n",
    "\n",
    "# source_df.columns = source_df.columns.str.replace(' ', '')\n",
    "source_df = source_df.rename(columns = TRANLSATION_LANGUAGES)\n",
    "\n",
    "#source_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with a subset of the data (just the line change details).\n",
    "\n",
    "Manually set the range of rows to copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_changes_df = source_df.iloc[DETAIL_START:]\n",
    "\n",
    "# Clean up by resetting the index and removing NaN rows\n",
    "line_changes_df = line_changes_df.reset_index(drop=True)\n",
    "line_changes_df = line_changes_df.dropna(subset=['en'])\n",
    "\n",
    "#line_changes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually adjust the data as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the last two rows: 55, 56\n",
    "# The row indices are different when accessing them as a Series versus the DataFrame\n",
    "\n",
    "# for column in line_changes_df:\n",
    "#     colSeries = line_changes_df[column]\n",
    "#     combinedText = colSeries.values[37] + colSeries.values[38]\n",
    "#     line_changes_df.at[55, colSeries.name] = combinedText\n",
    "#     line_changes_df.at[56, colSeries.name] = ''\n",
    "\n",
    "# line_changes_df = line_changes_df.drop([56])\n",
    "\n",
    "# line_changes_df = line_changes_df.reset_index(drop=True)\n",
    "\n",
    "# line_changes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the line number label by splitting based on the dash or em-dash\n",
    "# Create a new column 'label' that uses the first value from the split\n",
    "# Note that this value may be a line number or may be a text description\n",
    "\n",
    "# em-dash: –\n",
    "# normal dash: -\n",
    "\n",
    "line_changes_df['label'] = line_changes_df['en'].str.split('-').str[0].str.strip()\n",
    "\n",
    "#line_changes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove line numbers from details\n",
    "\n",
    "for column in line_changes_df:\n",
    "    for i in range(len(line_changes_df[column])):\n",
    "        if '՝' in line_changes_df.at[i, column]:\n",
    "            content = \"՝\".join(line_changes_df.at[i, column].split('՝')[1::])\n",
    "            line_changes_df.at[i, column] = content\n",
    "        elif ':' in line_changes_df.at[i, column]:\n",
    "            content = \":\".join(line_changes_df.at[i, column].split(':')[1::])\n",
    "            line_changes_df.at[i, column] = content\n",
    "        elif '–' in line_changes_df.at[i, column]:\n",
    "            content = \"-\".join(line_changes_df.at[i, column].split('–')[1::])\n",
    "            line_changes_df.at[i, column] = content\n",
    "        elif '-' in line_changes_df.at[i, column]:\n",
    "            content = \"-\".join(line_changes_df.at[i, column].split('-')[1::])\n",
    "            line_changes_df.at[i, column] = content\n",
    "\n",
    "# line_changes_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate rows that have two line numbers (based on the label column)\n",
    "\n",
    "def separate_rows(df, col, delim):\n",
    "    colSeries = df[col]\n",
    "    for item in colSeries:\n",
    "        if delim in str(item):\n",
    "            routes = item.split(delim)\n",
    "            matching_df = df.loc[df[col] == item]\n",
    "\n",
    "            matching_df = matching_df.append(matching_df)\n",
    "            matching_df = matching_df.reset_index(drop=True)\n",
    "            \n",
    "            matching_df.at[0, col] = routes[0].strip()\n",
    "            matching_df.at[1, col] = routes[1].strip()\n",
    "\n",
    "            df = df[df[col] != item]\n",
    "            df = df.append(matching_df)\n",
    "            df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "line_changes_df = separate_rows(line_changes_df, 'label', '/')\n",
    "\n",
    "#line_changes_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'line' that uses the value from column 'label' only if it is a digit\n",
    "def check_digit(x):\n",
    "    if x['label'].isdigit():\n",
    "        return x['label']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "line_changes_df['line'] = 0\n",
    "line_changes_df['line'] = line_changes_df.apply(check_digit, axis=1)\n",
    "\n",
    "# Set specific instance of the C & K Line Link, which is actually route number 857\n",
    "\n",
    "line_changes_df.loc[line_changes_df.label == 'C & K Line Link', 'line'] = 857\n",
    "\n",
    "# line_changes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ordered list of routes based on the current GTFS routes.txt file.  Combined lines are separated into their own rows\n",
    "routes_df = pd.read_csv(GTFS_ROUTES_URL, usecols=['route_short_name'], dtype={'route_short_name':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "split_routes_df = separate_rows(routes_df, 'route_short_name', '/')\n",
    "split_routes_df = split_routes_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = split_routes_df[(split_routes_df['route_short_name'].str.contains('Stadium'))].index\n",
    "\n",
    "routes_df = split_routes_df.drop(index_names) # drop the stadium routes\n",
    "routes_df = routes_df.astype({'route_short_name':'int'}) # cast to int\n",
    "\n",
    "# add back in the BRT lines since they don't have values for route_short_name\n",
    "routes_df = routes_df.append({'route_short_name':854}, ignore_index=True)\n",
    "routes_df = routes_df.append({'route_short_name':901}, ignore_index=True)\n",
    "routes_df = routes_df.append({'route_short_name':910}, ignore_index=True)\n",
    "routes_df = routes_df.append({'route_short_name':950}, ignore_index=True)\n",
    "\n",
    "routes_df = routes_df.sort_values(by='route_short_name').reset_index(drop=True) # sort routes in ascending order and reset the index\n",
    "routes_df = routes_df.reset_index() # create a new column with the reset index values\n",
    "\n",
    "# 'route_short_name' contains all routes separated\n",
    "# 'index' contains the number ordering of the routes\n",
    "\n",
    "# recast route_short_name to string for joining\n",
    "routes_df = routes_df.astype({'route_short_name':'str'})\n",
    "\n",
    "# rename columns\n",
    "\n",
    "routes_df = routes_df.rename(columns={'index':'order','route_short_name':'line'})\n",
    "\n",
    "# routes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order    119\n",
       "line     119\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not using this as of 11/22/2022\n",
    "# Read in full list of lines as pulled from the current GTFS routes.txt file (slightly modified)\n",
    "\n",
    "# routes_df = pd.read_csv('routes.csv', dtype={'line': str, 'order': int})\n",
    "# routes_df['line'] = routes_df['line'].astype(str)\n",
    "# routes_df['line'].apply(lambda x: x.strip())\n",
    "\n",
    "routes_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes using an outer join\n",
    "\n",
    "line_changes_df['line'] = line_changes_df['line'].astype(str)\n",
    "routes_and_line_changes_df = pd.merge(line_changes_df, routes_df, on='line', how='outer')\n",
    "\n",
    "routes_and_line_changes_df = routes_and_line_changes_df.sort_values(by='order')\n",
    "\n",
    "# confirm we have the correct final counts of lines with changes and total number of lines\n",
    "routes_and_line_changes_df = routes_and_line_changes_df.reset_index(drop=True)\n",
    "# routes_and_line_changes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>zh-tw</th>\n",
       "      <th>hy</th>\n",
       "      <th>ko</th>\n",
       "      <th>vi</th>\n",
       "      <th>ja</th>\n",
       "      <th>ru</th>\n",
       "      <th>label</th>\n",
       "      <th>line</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [en, es, zh-tw, hy, ko, vi, ja, ru, label, line, order]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see if any lines have no order value attached\n",
    "routes_and_line_changes_df.loc[routes_and_line_changes_df['order'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the PDFs\n",
    "import os\n",
    "\n",
    "#define the folders to look through\n",
    "# folders = os.listdir(\"../files/schedules\")\n",
    "\n",
    "#set an array for the file types\n",
    "timetables_list = []\n",
    "\n",
    "# from javascript file `rename.js`:\n",
    "# let newFileName = '';\n",
    "\n",
    "# let match = file.match(/^([0-9]*)( |_|-)*([0-9]*)( |_|-)*(TT)( |_|-)*([0-9]*)( |_|-)*([0-9]*)( |_|-)*([0-9]*)( |_|-)*.pdf$/);\n",
    "\n",
    "# if (match[3] == '') {\n",
    "#     newFileName = `${match[1]}_TT_${match[7]}-${match[9]}-${match[11]}.pdf`;\n",
    "# } else {\n",
    "#     newFileName = `${match[1]}-${match[3]}_TT_${match[7]}-${match[9]}-${match[11]}.pdf`;\n",
    "# }\n",
    "\n",
    "# if (file != newFileName) {\n",
    "#     renameSync(join(dir, file), join(dir, newFileName));\n",
    "#     console.log(`Renamed:\\n${file}\\nto\\n${newFileName}\\n`);\n",
    "# }\n",
    "\n",
    "#create a list of file types\n",
    "for root, dirs, files in os.walk(\"../files/schedules\"):\n",
    "    for filename in files:\n",
    "\n",
    "        lines = filename.replace(\" \",\"_\").split(\"_TT\")[0].split(\"-\")\n",
    "        for line in lines:\n",
    "            this_schedule = {}\n",
    "            this_schedule['line'] = line.lstrip(\"0\")\n",
    "            this_schedule['newSchedule'] = \"/files/schedules/\"+filename\n",
    "            timetables_list.append(this_schedule)\n",
    "\n",
    "schedule_df = pd.DataFrame(timetables_list)\n",
    "# schedule_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge schedules with list\n",
    "\n",
    "new_pdfs_and_routes_and_line_changes_df = pd.merge(routes_and_line_changes_df, schedule_df, on='line', how='outer')\n",
    "# new_pdfs_and_routes_and_line_changes_df.tail(20)\n",
    "\n",
    "# September 2022 shakeup: the 134 is a new line.  the 807 is the new crenshaw line\n",
    "# December 2022 shakeup: the 489 is missing from the GTFS routes and the 802 is the B Line (Red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull current schedule PDFs from the metro.net WP REST API\n",
    "\n",
    "wp_url = 'https://www.metro.net/wp-json/wp/v2/line-override'\n",
    "wp_df = pd.read_json(wp_url)\n",
    "\n",
    "wp_df = pd.DataFrame(wp_df['acf'])\n",
    "# wp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the line-override entries from WordPress that have a pdf_file.url value\n",
    "\n",
    "def get_urls(x):\n",
    "    temp_df = pd.json_normalize(x['acf'])\n",
    "    if 'pdf_file.url' in temp_df.columns:\n",
    "        return temp_df['pdf_file.url']\n",
    "    return\n",
    "\n",
    "wp_df_urls = wp_df.apply(get_urls, axis=1)\n",
    "\n",
    "wp_df_urls = wp_df_urls.dropna()\n",
    "\n",
    "wp_df_urls = wp_df_urls.rename(columns={0: \"currentSchedule\"})\n",
    "\n",
    "# wp_df_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any WordPress Line Overrides with no urls\n",
    "\n",
    "def get_no_urls(x):\n",
    "    temp_df = pd.json_normalize(x['acf'])\n",
    "    if 'pdf_file.url' not in temp_df.columns:\n",
    "        return temp_df['line_id']\n",
    "    return\n",
    "\n",
    "wp_df_no_urls = wp_df.apply(get_no_urls, axis=1)\n",
    "\n",
    "wp_df_no_urls = wp_df_no_urls.dropna()\n",
    "\n",
    "wp_df_no_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "5      None\n",
       "6      None\n",
       "7      None\n",
       "8      None\n",
       "9      None\n",
       "10     None\n",
       "11     None\n",
       "12     None\n",
       "13     None\n",
       "14     None\n",
       "15     None\n",
       "16     None\n",
       "17     None\n",
       "18     None\n",
       "19     None\n",
       "20     None\n",
       "21     None\n",
       "22     None\n",
       "23     None\n",
       "24     None\n",
       "25     None\n",
       "26     None\n",
       "27     None\n",
       "28     None\n",
       "29     None\n",
       "30     None\n",
       "31     None\n",
       "32     None\n",
       "33     None\n",
       "34     None\n",
       "35     None\n",
       "36     None\n",
       "37     None\n",
       "38     None\n",
       "39     None\n",
       "40     None\n",
       "41     None\n",
       "42     None\n",
       "43     None\n",
       "44     None\n",
       "45     None\n",
       "46     None\n",
       "47     None\n",
       "48     None\n",
       "49     None\n",
       "50     None\n",
       "51     None\n",
       "52     None\n",
       "53     None\n",
       "54     None\n",
       "55     None\n",
       "56     None\n",
       "57     None\n",
       "58     None\n",
       "59     None\n",
       "60     None\n",
       "61     None\n",
       "62     None\n",
       "63     None\n",
       "64     None\n",
       "65     None\n",
       "66     None\n",
       "67     None\n",
       "68     None\n",
       "69     None\n",
       "70     None\n",
       "71     None\n",
       "72     None\n",
       "73     None\n",
       "74     None\n",
       "75     None\n",
       "76     None\n",
       "77     None\n",
       "78     None\n",
       "79     None\n",
       "80     None\n",
       "81     None\n",
       "82     None\n",
       "83     None\n",
       "84     None\n",
       "85     None\n",
       "86     None\n",
       "87     None\n",
       "88     None\n",
       "89     None\n",
       "90     None\n",
       "91     None\n",
       "92     None\n",
       "93     None\n",
       "94     None\n",
       "95     None\n",
       "96     None\n",
       "97     None\n",
       "98     None\n",
       "99     None\n",
       "100    None\n",
       "101    None\n",
       "102    None\n",
       "103    None\n",
       "104    None\n",
       "105    None\n",
       "106    None\n",
       "107    None\n",
       "108    None\n",
       "109    None\n",
       "110    None\n",
       "111    None\n",
       "112    None\n",
       "113    None\n",
       "114    None\n",
       "115    None\n",
       "116    None\n",
       "117    None\n",
       "118    None\n",
       "119    None\n",
       "120    None\n",
       "121    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the line and add it to a separate column\n",
    "\n",
    "def get_lines(x):\n",
    "    split_url = x['currentSchedule'].split('/')\n",
    "    filename = split_url[len(split_url)-1].replace(' ', '_')\n",
    "    line = ''\n",
    "\n",
    "    if '_-' in filename:\n",
    "        filename = filename.replace('_-', '_')\n",
    "\n",
    "    if '_TT' in filename:\n",
    "        line = filename.split('_TT')[0].lstrip('0')\n",
    "    elif '-TT' in filename:\n",
    "        line = filename.split('-TT')[0].lstrip('0')\n",
    "    elif '.pdf' in filename:\n",
    "        line = filename.split('_')[0].lstrip('0')\n",
    "    else:\n",
    "        line = filename\n",
    "    x['line'] = line\n",
    "    return\n",
    "\n",
    "current_pdfs_list = []\n",
    "\n",
    "wp_df_urls['line'] = ''\n",
    "wp_df_urls.apply(get_lines, axis=1)\n",
    "\n",
    "# wp_df_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wp_df_urls = separate_rows(wp_df_urls, 'line', '_')\n",
    "\n",
    "wp_df_urls = wp_df_urls.drop_duplicates(subset=['line'])\n",
    "\n",
    "colSeries = wp_df_urls['line']\n",
    "\n",
    "for item in colSeries:\n",
    "    if '-' in item:\n",
    "        routes = item.split('-')\n",
    "        matching_df = wp_df_urls.loc[wp_df_urls['line'] == item]\n",
    "        matching_df = matching_df.append(matching_df)\n",
    "        matching_df = matching_df.reset_index(drop=True)\n",
    "\n",
    "        matching_df.at[0, 'line'] = routes[0].strip().lstrip('0')\n",
    "        matching_df.at[1, 'line'] = routes[1].strip().lstrip('0')\n",
    "\n",
    "        wp_df_urls = wp_df_urls[wp_df_urls['line'] != item]\n",
    "        wp_df_urls = wp_df_urls.append(matching_df)\n",
    "        wp_df_urls = wp_df_urls.reset_index(drop=True)\n",
    "\n",
    "# wp_df_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine current schedules \n",
    "\n",
    "details_df = pd.merge(new_pdfs_and_routes_and_line_changes_df, wp_df_urls, on='line', how='left')\n",
    "\n",
    "# details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>zh-tw</th>\n",
       "      <th>hy</th>\n",
       "      <th>ko</th>\n",
       "      <th>vi</th>\n",
       "      <th>ja</th>\n",
       "      <th>ru</th>\n",
       "      <th>label</th>\n",
       "      <th>line</th>\n",
       "      <th>order</th>\n",
       "      <th>newSchedule</th>\n",
       "      <th>currentSchedule</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [en, es, zh-tw, hy, ko, vi, ja, ru, label, line, order, newSchedule, currentSchedule]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any lines that are missing a currentSchedule\n",
    "# this would indicate a problem in WordPress that needs to be fixed\n",
    "\n",
    "details_df.loc[details_df['currentSchedule'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# October 2022 shakeup: manual adjustment for line 534, which is being renamed to the 134\n",
    "\n",
    "# details_df.loc[details_df['line'] == '534', 'newSchedule'] = details_df.loc[details_df['line'] == '134', 'newSchedule'].values[0]\n",
    "\n",
    "# details_df.loc[details_df['line'] == '534']\n",
    "\n",
    "# details_df = details_df[details_df['line'] != '134']\n",
    "\n",
    "# details_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "5      None\n",
       "6      None\n",
       "7      None\n",
       "8      None\n",
       "9      None\n",
       "10     None\n",
       "11     None\n",
       "12     None\n",
       "13     None\n",
       "14     None\n",
       "15     None\n",
       "16     None\n",
       "17     None\n",
       "18     None\n",
       "19     None\n",
       "20     None\n",
       "21     None\n",
       "22     None\n",
       "23     None\n",
       "24     None\n",
       "25     None\n",
       "26     None\n",
       "27     None\n",
       "28     None\n",
       "29     None\n",
       "30     None\n",
       "31     None\n",
       "32     None\n",
       "33     None\n",
       "34     None\n",
       "35     None\n",
       "36     None\n",
       "37     None\n",
       "38     None\n",
       "39     None\n",
       "40     None\n",
       "41     None\n",
       "42     None\n",
       "43     None\n",
       "44     None\n",
       "45     None\n",
       "46     None\n",
       "47     None\n",
       "48     None\n",
       "49     None\n",
       "50     None\n",
       "51     None\n",
       "52     None\n",
       "53     None\n",
       "54     None\n",
       "55     None\n",
       "56     None\n",
       "57     None\n",
       "58     None\n",
       "59     None\n",
       "60     None\n",
       "61     None\n",
       "62     None\n",
       "63     None\n",
       "64     None\n",
       "65     None\n",
       "66     None\n",
       "67     None\n",
       "68     None\n",
       "69     None\n",
       "70     None\n",
       "71     None\n",
       "72     None\n",
       "73     None\n",
       "74     None\n",
       "75     None\n",
       "76     None\n",
       "77     None\n",
       "78     None\n",
       "79     None\n",
       "80     None\n",
       "81     None\n",
       "82     None\n",
       "83     None\n",
       "84     None\n",
       "85     None\n",
       "86     None\n",
       "87     None\n",
       "88     None\n",
       "89     None\n",
       "90     None\n",
       "91     None\n",
       "92     None\n",
       "93     None\n",
       "94     None\n",
       "95     None\n",
       "96     None\n",
       "97     None\n",
       "98     None\n",
       "99     None\n",
       "100    None\n",
       "101    None\n",
       "102    None\n",
       "103    None\n",
       "104    None\n",
       "105    None\n",
       "106    None\n",
       "107    None\n",
       "108    None\n",
       "109    None\n",
       "110    None\n",
       "111    None\n",
       "112    None\n",
       "113    None\n",
       "114    None\n",
       "115    None\n",
       "116    None\n",
       "117    None\n",
       "118    None\n",
       "119    None\n",
       "120    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual filling in of label field\n",
    "\n",
    "def apply_line_labels(row):\n",
    "    # if pd.isna(details_df.at[row.name, 'label']):\n",
    "    line_value = details_df.at[row.name, 'line']\n",
    "\n",
    "    if '802' in line_value:\n",
    "        details_df.at[row.name, 'label'] = 'B Line'           \n",
    "    elif '807' in line_value:\n",
    "        details_df.at[row.name, 'label'] = 'K Line'\n",
    "    elif '854' in line_value:\n",
    "        details_df.at[row.name, 'label'] = 'L Line Shuttle'\n",
    "    elif '857' in line_value:\n",
    "        details_df.at[row.name, 'label'] = 'C & K Line Link'\n",
    "    elif '901' in line_value:\n",
    "        details_df.at[row.name, 'label'] = 'G Line'\n",
    "    elif '910' in line_value:\n",
    "        details_df.at[row.name, 'label'] = 'J Line (910)'\n",
    "    elif '950' in line_value:\n",
    "        details_df.at[row.name, 'label'] = 'J Line (950)'\n",
    "    else:\n",
    "        details_df.at[row.name, 'label'] = line_value\n",
    "    return\n",
    "\n",
    "details_df.apply(apply_line_labels, axis=1)\n",
    "\n",
    "# details_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort based on line number\n",
    "# Must cast the line column to int for sorting\n",
    "details_df = details_df.astype({'line':int})\n",
    "details_df = details_df.sort_values(by='line').reset_index(drop=True)\n",
    "details_df = details_df.astype({'line':str})\n",
    "# details_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = source_df.loc[SUMMARY_START:SUMMARY_END].reset_index(drop=True)\n",
    "# summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will need to customize for each shakeup\n",
    "\n",
    "for column in summary_df:\n",
    "    colSeries = summary_df[column]\n",
    "\n",
    "    combinedText = '<p>' + colSeries.values[1] + '</p><p>' + colSeries.values[2] + '</p><p>' + colSeries.values[3] + '</p>'\n",
    "    summary_df.at[1, colSeries.name] = combinedText\n",
    "\n",
    "summary_df = summary_df.drop([2, 3])\n",
    "summary_df = summary_df.reset_index(drop=True)\n",
    "summary_df.at[0, 'type'] = 'description'\n",
    "summary_df.at[1, 'type'] = 'details'\n",
    "summary_df.at[2, 'type'] = 'description'\n",
    "\n",
    "# summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_df = source_df.loc[INTRO_ROWS].reset_index(drop=True)\n",
    "# intro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>zh-tw</th>\n",
       "      <th>hy</th>\n",
       "      <th>ko</th>\n",
       "      <th>vi</th>\n",
       "      <th>ja</th>\n",
       "      <th>ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metro is restoring full service levels.</td>\n",
       "      <td>Metro está restaurando los niveles completos de servicio.</td>\n",
       "      <td>Metro將對巴士服務進行變更，以恢復整體的服務水準。</td>\n",
       "      <td>Metro-ն փոխում է ավտոբուսների սպասարկումը՝ վերականգնելու սպասարկման ամբողջական մակարդակները:</td>\n",
       "      <td>Metro는 전체 서비스 수준을 복구하기 위해 버스편 운행 변경을 진행하고 있습니다.</td>\n",
       "      <td>Metro sắp tiến hành thay đổi dịch vụ xe buýt để khôi phục mức dịch vụ đầy đủ.</td>\n",
       "      <td>Metroは、完全なサービスレベルに復旧するために、バス運行サービスの改正を実施いたします。</td>\n",
       "      <td>Metro вносит ряд изменений в график движения автобусов для возобновления полного обслуживания.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New schedules beginning December 11, 2022. Metro is restoring full service levels, which were reduced in early 2022 due to operator shortages. Service changes\\nto affected bus lines will begin Sunday, December 11. Check specific bus line schedules at metro.net/mybus.</td>\n",
       "      <td>Los nuevos horarios comienzan el 11 de deciembre 2022. Metro está restaurando los niveles de servicio completo que se redujeron a principios de 2022 debido a la falta de operadores. Los cambios en el servicio de las líneas de autobús afectadas comenzarán el domingo 11 de diciembre. Consulte los horarios de las líneas de autobús específicas en metro.net/mybus.</td>\n",
       "      <td>最新班次時間表將於2022年12月11日生效。 Metro即將在12月11日週日更動其巴士線路，藉此向搭乘者提供更多班次與更加穩定的服務。此服務所進行的變更，使得所有在2022年年初縮減的整體服務水準得以全面恢復。欲知更多詳情，請至metro.net/mybus查看詳細的巴士線路時間表。</td>\n",
       "      <td>Նոր ժամանակացույցեր՝ սկսած 2022 թ-ի դեկտեմբերի 11-ից: Metro-ն կիրակի օրը՝ դեկտեմբերի 11-ից սկսած, որոշ երթուղիների գծերում փոփոխություններ է կատարում՝ մեր ուղևորներին ավելի հաճախակի և հուսալի ծառայություններ մատուցելու համար: Ծառայությունների այս փոփոխությունն ավարտում է 2022 թվականին ավելի վաղ նվազեցված սպասարկման ամբողջական մակարդակների վերականգնումը: Լրացուցիչ մանրամասների համար այցելեք metro.net/mybus կայքը՝ ավտոբուսային գծի հատուկ ժամանակացույցերի հատվածը:</td>\n",
       "      <td>2022년 12월 11일부터 새로운 일정이 적용됩니다. Metro는 승객들에게 안정적으로 더 많은 서비스를 제공하기 위해 12월 11일 일요일부터 일부 버스 노선의 운행 서비스 변경을 진행하고 있습니다. 이번 서비스 변경으로 2022년 초에 축소되었던 전체 서비스 수준의 복구가 완료됩니다. 자세한 내용은 metro.net/mybus에서 구체적인 버스 노선 일정을 확인하십시오.</td>\n",
       "      <td>Lịch trình mới sẽ bắt đầu từ ngày 11 tháng 12 năm 2022. Metro sắp tiến hành thay đổi dịch vụ đối với một số tuyến xe buýt kể từ Chủ Nhật, ngày 11 tháng 12, để cung cấp cho hành khách các dịch vụ thường xuyên và đáng tin cậy hơn. Sự thay đổi dịch vụ này sẽ hoàn thành việc khôi phục mức dịch vụ đầy đủ mà đã trước đó đã bị giảm đi hồi năm 2022. Để biết thêm thông tin chi tiết, hãy xem lịch trình cụ thể của các tuyến xe buýt tại metro.net/mybus.</td>\n",
       "      <td>新しいダイヤは、2022年12月11日より運行開始となります。 Metroは、乗客の皆様に向けて運行本数の多い信頼できるサービスを提供するべく、12月11日（日）より一部の路線において運行サービスの改正を実施いたします。この改正により、2022年のある時点より低下しておりましたサービスレベルが完全なレベルに復旧します。詳細につきましては、metro.net/mybusにて路線別時刻表をご覧ください。</td>\n",
       "      <td>Новый график будет действовать с 11 декабря 2022 г. С воскресенья, 11 декабря, вступают в силу изменения в графике движения некоторых автобусных маршрутов Metro. Это позволит сделать наши рейсы более частыми, а перевозки — более надежными и завершить восстановление полного уровня обслуживания, представленного в начале 2022 года. Чтобы узнать больше, ознакомьтесь с графиком движения конкретных автобусных маршрутов на странице metro.net/mybus.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                            en  \\\n",
       "0                                                                                                                                                                                                                                      Metro is restoring full service levels.   \n",
       "1  New schedules beginning December 11, 2022. Metro is restoring full service levels, which were reduced in early 2022 due to operator shortages. Service changes\\nto affected bus lines will begin Sunday, December 11. Check specific bus line schedules at metro.net/mybus.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                          es  \\\n",
       "0                                                                                                                                                                                                                                                                                                                  Metro está restaurando los niveles completos de servicio.   \n",
       "1  Los nuevos horarios comienzan el 11 de deciembre 2022. Metro está restaurando los niveles de servicio completo que se redujeron a principios de 2022 debido a la falta de operadores. Los cambios en el servicio de las líneas de autobús afectadas comenzarán el domingo 11 de diciembre. Consulte los horarios de las líneas de autobús específicas en metro.net/mybus.   \n",
       "\n",
       "                                                                                                                                               zh-tw  \\\n",
       "0                                                                                                                        Metro將對巴士服務進行變更，以恢復整體的服務水準。   \n",
       "1  最新班次時間表將於2022年12月11日生效。 Metro即將在12月11日週日更動其巴士線路，藉此向搭乘者提供更多班次與更加穩定的服務。此服務所進行的變更，使得所有在2022年年初縮減的整體服務水準得以全面恢復。欲知更多詳情，請至metro.net/mybus查看詳細的巴士線路時間表。    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   hy  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                        Metro-ն փոխում է ավտոբուսների սպասարկումը՝ վերականգնելու սպասարկման ամբողջական մակարդակները:   \n",
       "1  Նոր ժամանակացույցեր՝ սկսած 2022 թ-ի դեկտեմբերի 11-ից: Metro-ն կիրակի օրը՝ դեկտեմբերի 11-ից սկսած, որոշ երթուղիների գծերում փոփոխություններ է կատարում՝ մեր ուղևորներին ավելի հաճախակի և հուսալի ծառայություններ մատուցելու համար: Ծառայությունների այս փոփոխությունն ավարտում է 2022 թվականին ավելի վաղ նվազեցված սպասարկման ամբողջական մակարդակների վերականգնումը: Լրացուցիչ մանրամասների համար այցելեք metro.net/mybus կայքը՝ ավտոբուսային գծի հատուկ ժամանակացույցերի հատվածը:    \n",
       "\n",
       "                                                                                                                                                                                                                     ko  \\\n",
       "0                                                                                                                                                                       Metro는 전체 서비스 수준을 복구하기 위해 버스편 운행 변경을 진행하고 있습니다.   \n",
       "1  2022년 12월 11일부터 새로운 일정이 적용됩니다. Metro는 승객들에게 안정적으로 더 많은 서비스를 제공하기 위해 12월 11일 일요일부터 일부 버스 노선의 운행 서비스 변경을 진행하고 있습니다. 이번 서비스 변경으로 2022년 초에 축소되었던 전체 서비스 수준의 복구가 완료됩니다. 자세한 내용은 metro.net/mybus에서 구체적인 버스 노선 일정을 확인하십시오.    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                               vi  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                   Metro sắp tiến hành thay đổi dịch vụ xe buýt để khôi phục mức dịch vụ đầy đủ.   \n",
       "1  Lịch trình mới sẽ bắt đầu từ ngày 11 tháng 12 năm 2022. Metro sắp tiến hành thay đổi dịch vụ đối với một số tuyến xe buýt kể từ Chủ Nhật, ngày 11 tháng 12, để cung cấp cho hành khách các dịch vụ thường xuyên và đáng tin cậy hơn. Sự thay đổi dịch vụ này sẽ hoàn thành việc khôi phục mức dịch vụ đầy đủ mà đã trước đó đã bị giảm đi hồi năm 2022. Để biết thêm thông tin chi tiết, hãy xem lịch trình cụ thể của các tuyến xe buýt tại metro.net/mybus.    \n",
       "\n",
       "                                                                                                                                                                                                           ja  \\\n",
       "0                                                                                                                                                              Metroは、完全なサービスレベルに復旧するために、バス運行サービスの改正を実施いたします。   \n",
       "1  新しいダイヤは、2022年12月11日より運行開始となります。 Metroは、乗客の皆様に向けて運行本数の多い信頼できるサービスを提供するべく、12月11日（日）より一部の路線において運行サービスの改正を実施いたします。この改正により、2022年のある時点より低下しておりましたサービスレベルが完全なレベルに復旧します。詳細につきましては、metro.net/mybusにて路線別時刻表をご覧ください。    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                               ru  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                  Metro вносит ряд изменений в график движения автобусов для возобновления полного обслуживания.  \n",
       "1  Новый график будет действовать с 11 декабря 2022 г. С воскресенья, 11 декабря, вступают в силу изменения в графике движения некоторых автобусных маршрутов Metro. Это позволит сделать наши рейсы более частыми, а перевозки — более надежными и завершить восстановление полного уровня обслуживания, представленного в начале 2022 года. Чтобы узнать больше, ознакомьтесь с графиком движения конкретных автобусных маршрутов на странице metro.net/mybus.   "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the rows as needed so that:\n",
    "# row 0 is the Intro Header\n",
    "# row 1 is the Intro Details\n",
    "\n",
    "for col in intro_df.columns:\n",
    "    intro_df.at[1, col] = intro_df.at[1, col] + ' ' + intro_df.at[2, col]\n",
    "\n",
    "intro_df = intro_df.drop(2)\n",
    "\n",
    "intro_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_sentence(row):\n",
    "#     if row.name == 4:\n",
    "#         for col in intro_df.columns:\n",
    "#             if ':' in row[col]:\n",
    "#                 intro_df.at[4, col] = row[col].split(':')[0].replace('\"', '') + ':'\n",
    "#             elif '。' in row[col]:\n",
    "#                 intro_df.at[4, col] = row[col].split('。')[0] + '。'\n",
    "#             else:\n",
    "#                 if col == 'ru':\n",
    "#                     intro_df.at[4, col] = row[col].split('.')[0] + '. ' + row[col].split('.')[1] + '.'\n",
    "#                 else:\n",
    "#                     intro_df.at[4, col] = row[col].split('.')[0] + '. '\n",
    "#     return\n",
    "\n",
    "# intro_df.apply(remove_sentence, axis=1)\n",
    "\n",
    "# intro_df = intro_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set an array for the file types\n",
    "language_list = {\n",
    "    'English': {\n",
    "        'label': 'English',\n",
    "        'order': 0\n",
    "    },\n",
    "    'Spanish': {\n",
    "        'label': 'Español (Spanish)',\n",
    "        'order': 1\n",
    "    },\n",
    "    'Chinese': {\n",
    "        'label': '中文 (Chinese Traditional)',\n",
    "        'order': 2\n",
    "    },\n",
    "    'Korean': {\n",
    "        'label': '한국어 (Korean)',\n",
    "        'order': 3\n",
    "    },\n",
    "    'Vietnamese': {\n",
    "        'label': 'Tiếng Việt (Vietnamese)',\n",
    "        'order': 4\n",
    "    },\n",
    "    'Japanese': {\n",
    "        'label': '日本語 (Japanese)',\n",
    "        'order': 5\n",
    "    },\n",
    "    'Russian': {\n",
    "        'label': 'русский (Russian)',\n",
    "        'order': 6\n",
    "    },\n",
    "    'Armenian': {\n",
    "        'label': 'Армянский (Armenian)',\n",
    "        'order': 7\n",
    "    }\n",
    "}\n",
    "    \n",
    "takeones_list = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create a list of file types\n",
    "for root, dirs, files in os.walk(\"../files/takeones\"):\n",
    "    for filename in files:\n",
    "        lang = filename.split('_-_')[1].split('.')[0]\n",
    "        takeones_list[language_list[lang]['order']] = {\n",
    "            'text': language_list[lang]['label'],\n",
    "            'url': '/files/takeones/' + filename\n",
    "        }\n",
    "        \n",
    "# takeones_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "takeones_dict = {\n",
    "    'takeones': {\n",
    "        'description': 'Download a PDF version of this page in ',\n",
    "        'files': takeones_list\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = summary_df[['type','en']]\n",
    "# temp = temp.rename(columns={'en': 'description'})\n",
    "\n",
    "# for i in range(len(temp['description'])):\n",
    "#     if temp.loc[i, 'type'] == 'details':\n",
    "#         temp.loc[i-1, 'details'] = temp.loc[i, 'description']\n",
    "#         temp = temp.drop(i)\n",
    "\n",
    "# temp = temp.reset_index(drop=True)\n",
    "# temp = temp.drop('type', axis=1)\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details_df.to_json('lineChangesOctober.json', orient='records')\n",
    "\n",
    "details_df = details_df.fillna('')\n",
    "langs = ['en','es','zh-tw','ko','vi','ja','ru','hy']\n",
    "all_langs_results_arr = []\n",
    "\n",
    "for lang in langs:\n",
    "    ### Intro Section\n",
    "    temp_intro_df = intro_df[lang]\n",
    "    temp_intro_df = temp_intro_df.rename(index={0: 'header', 1: 'details'})\n",
    "\n",
    "    temp_intro_dict = temp_intro_df.to_dict()\n",
    "    temp_intro_dict = {\n",
    "        'intro': temp_intro_dict\n",
    "    }\n",
    "\n",
    "    ### Summary Section\n",
    "    temp_summary_df = summary_df[['type',lang]]\n",
    "    temp_summary_df = temp_summary_df.rename(columns={lang: 'description'})\n",
    "\n",
    "    for i in range(len(temp_summary_df['description'])):\n",
    "        if temp_summary_df.loc[i, 'type'] == 'details':\n",
    "            temp_summary_df.loc[i-1, 'details'] = temp_summary_df.loc[i, 'description']\n",
    "            temp_summary_df = temp_summary_df.drop(i)\n",
    "        # if i % 2 == 0:\n",
    "        #     temp_summary_df.loc[i, 'details'] = temp_summary_df.loc[i+1, 'description']\n",
    "        # else:\n",
    "        #     temp_summary_df = temp_summary_df.drop(i)\n",
    "    temp_summary_df = temp_summary_df.drop('type', axis=1)\n",
    "    temp_summary_df = temp_summary_df.fillna('')\n",
    "\n",
    "    temp_summary_dict = temp_summary_df.to_dict(orient='records')\n",
    "    temp_summary_df = pd.DataFrame({'summary': temp_summary_dict})\n",
    "\n",
    "    temp_summary_dict = temp_summary_df.to_dict(orient='list')\n",
    "\n",
    "    ### Details Section\n",
    "    temp_details_df = details_df[[lang, 'line', 'label', 'newSchedule', 'currentSchedule']]\n",
    "    temp_details_df = temp_details_df.rename(columns={lang: 'description'})\n",
    "    temp_details_dict = temp_details_df.to_dict(orient='records')\n",
    "\n",
    "    temp_details_df = pd.DataFrame({'details': temp_details_dict})\n",
    "    temp_details_dict = temp_details_df.to_dict(orient='list')\n",
    "\n",
    "    # use the dictionary unpacking notation: **\n",
    "    # to create a new dictionary comprised of the key/value pairs from the other dictionaries\n",
    "    result_dict = temp_intro_dict\n",
    "    result_dict.update(takeones_dict)\n",
    "    result_dict.update(temp_summary_dict)\n",
    "    result_dict.update(temp_details_dict)\n",
    "    \n",
    "    all_langs_results_arr.append({\n",
    "        'lang': lang,\n",
    "        'content': result_dict\n",
    "    })\n",
    "\n",
    "# print(all_langs_results_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# all_langs_results_json = json.dumps(all_langs_results_dict)\n",
    "# print(all_langs_results_json)\n",
    "\n",
    "with open('../data/allChanges.json', 'w') as json_file:\n",
    "    json.dump(all_langs_results_arr, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
